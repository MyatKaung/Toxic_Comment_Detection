# Toxic_Comment_Classification

One area of study in NLP is to classify negative online behaviors, like toxic comments (i.e. comments that are rude, disrespectful or otherwise likely to make someone leave a discussion). So far we have seen a range of publicly available models served through the Perspective API, including toxicity. 

In this notebook, I have built a model thatâ€™s capable of detecting different types of of toxicity like threats, obscenity, insults, and identity-based hate. Finally, I have used Gradio Web for using as a web link so that people can easily classify the comments.
